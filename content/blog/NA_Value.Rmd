---
title: "Tratamento de Dados Ausentes"
date: "2025-02-20"
categories: ["R"]
tags: ["Curadoria de Dados", "NA Value", "Machine Learning", "Random Forest"]
output: 
  html_document:
    toc: true
    toc_float: true
    number_sections: true
    theme: flatly
    highlight: "textmate"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Tratamento de Valores Ausentes(NA) no Programa R

A detecção e o tratamento de dados ausentes são componentes essenciais
em qualquer processo de análise de dados, uma vez que a presença de
valores faltantes pode distorcer os resultados de forma significativa. A
qualidade e a integridade dos dados são fundamentais para garantir que
as conclusões obtidas a partir das análises sejam confiáveis e
representativas da realidade que se deseja investigar.

## Como ocorrem os dados ausentes?

Dados ausentes podem ocorrer por diversos motivos, como erros de coleta,
falhas técnicas, ou até mesmo por escolhas experimentais. Esses valores
faltantes, se não tratados adequadamente, podem levar a viéses nas
estimativas, perda de poder estatístico e redução da precisão dos
modelos preditivos.

## Como resolver esse problema?

A forma como lidamos com os dados ausentes pode afetar diretamente a
validade das análises subsequentes. Estratégias como remoção de dados
ausentes, imputação ou modelagem específica para dados ausentes são
frequentemente utilizadas para contornar esse problema. A escolha da
abordagem depende do tipo de dados, do volume de valores ausentes e dos
objetivos da pesquisa. O objetivo final é garantir que as conclusões
extraídas não sejam enviesadas ou imprecisas devido à presença desses
dados faltantes, proporcionando assim análises mais robustas e decisões
mais informadas.

# Tratamento dos dados no R

## Detecção de valores ausentes:

A Função que mostra uma tabela bruta com valores lógicos identificando
células vazias é

> is.na(Objeto))

Essa função não é tao interessante para ser usada inicialmente na nossa
curadoria de dados, pra isso, podemos utilizar uma função que irá nos
responder logicamente (TRUE or FALSE) se o nosso conjunto de dados tem
ou não valores ausentes, para isso podemos contar com a ajuda da função
*any*()

> any(is.na(Objeto))

A partir do resultado dessa função, podemos perguntar ao R quais linhas
e colunas estão os valores ausentes:

> which(is.na(Objeto), arr.ind = TRUE)

Se o nosso conjunto de dados possuir muitos valores ausentes, a lista
dessa chamada de função será grande, logo, é mais intuitivo perguntar ao
R quantos valores ausentes cada coluna que o meu conjunto de dados
possui:

> colSums(is.na(Objeto))

## O que fazer com os valores ausentes encontrados?

Existem três alternativas que podemos utilizar para nos livrar dessa
incoveniência, sendo elas: excluir, substituir ou estimar dados em
detrimento dos valores ausentes. Escolher entre cada uma dessas opções
dependerá da quantidade de valores ausentes encontrados no meu conjunto
de dados.

### Poucos NA - Substituir esses valores pela média, mediana ou valor fixo

#### Média

```{r, eval=FALSE}
for (col in colnames(SeuDataFrame)) { if (is.numeric(SeuDataFrame[[col]])) { SeuDataFrame[[col]][is.na(SeuDataFrame[[col]])] <- mean(SeuDataFrame[[col]], na.rm = TRUE) } }
```

#### Valor Fixo, substituir por 0

```{r, eval=FALSE}
SeuDataFrame[is.na(SeuDataFrame)] <- 0
```

### Muitos NA em poucas colunas - Remover as colunas

```{r, eval=FALSE}
SeuDataFrame <- SeuDataFrame[, colSums(is.na(SeuDataFrame)) == 0] # Remove todas as colunas com qualquer NA

SeuDataFrame <- SeuDataFrame[, colMeans(is.na(SeuDataFrame)) < 0.5] # se quiser remover apenas colunas com mais de 50% de NA:
```

### Muitos NA dispersos em várias linhas - Remover as linhas

```{r, eval=FALSE}
SeuDataFrame <- na.omit(SeuDataFrame) # Remove todas as linhas que tenham pelo menos um NA
```

### Para dados muito importantes podemos substituir o NA pelo valor anterior (**isso para séries temporais**) ou podemos utilizar Modelos de Imputação (**interpolação ou machine learning**)

#### Séries Temporais:

```{r, eval=FALSE}
library(zoo) 
SeuDataFrame <- na.locf(SeuDataFrame) # Preenche com o último valor não-NA
```

#### Modelos de Imputação:

Os **modelos de imputação** são técnicas utilizadas para substituir
valores ausentes em um conjunto de dados por estimativas baseadas nas
informações disponíveis. A imputação é uma etapa crucial em processos
analíticos, especialmente quando a quantidade de dados ausentes é
significativa. Ela visa melhorar a qualidade dos dados, preservando sua
integridade e evitando que a perda de informações prejudique as
conclusões das análises.

Existem várias abordagens para imputação, que podem ser classificadas em
**simples** ou **complexas**. A escolha do modelo de imputação depende
do tipo de dados, da natureza dos valores ausentes e do impacto
potencial na análise. Abaixo, estão algumas das principais abordagens:

##### 1. **Imputação por Média/Mediana/Moda (Imputação Simples)**

A imputação simples é uma das mais diretas e consiste em substituir os
valores ausentes por uma estatística central dos dados observados.

-   **Média**: Substituir valores ausentes pela média dos valores
    observados em uma variável numérica.

-   **Mediana**: Usada especialmente quando os dados são assimétricos,
    substituindo valores ausentes pela mediana.

-   **Moda**: Para dados categóricos, os valores ausentes podem ser
    substituídos pela moda, ou seja, o valor mais frequente.

**Limitações**:

-   Não leva em consideração as correlações entre variáveis.

-   Pode reduzir a variabilidade dos dados e introduzir viés,
    especialmente em distribuições assimétricas.

##### 2. **Imputação por Regressão**

Este modelo utiliza uma relação estatística entre a variável com dados
ausentes e outras variáveis do conjunto de dados para prever os valores
ausentes.

-   **Imputação por Regressão Linear**: Usa uma equação de regressão
    linear para prever os valores ausentes com base em outras variáveis
    numéricas.

-   **Imputação por Regressão Logística**: Utilizada para variáveis
    categóricas, onde a relação entre a variável ausente e as demais é
    modelada por regressão logística.

**Limitações**:

-   Supõe que a relação entre as variáveis é linear (no caso de
    regressão linear).

-   Pode ser inadequada se a relação entre as variáveis for complexa ou
    não-linear.

##### 3. **Imputação por K-Vizinhos Mais Próximos (KNN)**

A imputação por KNN substitui os valores ausentes com base em uma média
ponderada dos valores dos **k vizinhos mais próximos**. Este método leva
em consideração a similaridade entre os casos para preencher os valores
ausentes.

-   **KNN Imputation**: A variável ausente é estimada pela média (ou
    mediana) dos valores das observações mais próximas, com base em uma
    medida de distância (por exemplo, distância Euclidiana).

**Limitações**:

-   Exige o cálculo de distâncias entre todas as observações.

-   A escolha de "k" pode influenciar os resultados.

**Exemplo no R:**

```{r, eval=FALSE}
# Carregue o pacote
library(VIM)
library(missForest)

# Carregar o conjunto de dados iris - Não existem valores ausentes aqui
data(iris)

# Definir uma semente para reprodutibilidade
set.seed(123)

# Introduzir valores ausentes aleatórios
iris_ausentes <- prodNA(iris, noNA = 0.2) # Função para adicionar valores ausentes em posições aleatórias, o valor 0.2 produz muitos valores ausentes, tente reduzir esse valor para testar.

# Imputação com KNN
iris_imputados <- kNN(iris_ausentes, k = 5)  # k=5 significa que vamos considerar os 5 vizinhos mais próximos
```

**Exibir os dados estimados e reais lado a lado\
**

```{r, eval=FALSE}
# Criar uma máscara dos valores que foram imputados
mascara_NA <- is.na(iris_ausentes)

# Extrair apenas os valores imputados e seus valores reais correspondentes
valores_imputados <- iris_imputados[mascara_NA]
valores_reais <- iris[mascara_NA]

# Criar um data frame para visualizar as comparações
comparacao <- data.frame(
  Valor_Real = valores_reais,
  Valor_Imputado = valores_imputados
)

# Mostrar a tabela de comparação
print(comparacao)
```

No próximo tópico será abordado testes para verificar o poder do teste e
o tamanho de efeito, tente aplicar aqui também para verificar a
confiabilidade da estimativa.

##### 4. **Imputação por Modelos Baseados em Árvores (ex: MissForest)**

O **MissForest** é um modelo de imputação baseado em **árvores de
decisão**. Ele trata dados ausentes como variáveis a serem preditas e
usa o algoritmo **Random Forest** para prever esses valores ausentes. A
imputação é feita de forma iterativa, onde os valores imputados em cada
iteração são utilizados para ajustar o modelo até que uma solução
estável seja alcançada.

**Vantagens**:

-   Não assume distribuições específicas para os dados (flexível).

-   Lida bem com variáveis categóricas e numéricas simultaneamente.

**Limitações**:

-   Requer mais poder computacional devido à complexidade dos algoritmos
    de árvores.

-   Pode ser mais lento para grandes conjuntos de dados.

```{r, eval=FALSE}
library(missForest) 
SeuDataFrame <- missForest(SeuDataFrame)$ximp #Salva um novo data.frame com dados estimados
SeuDataFrame$OOBerror # estimativa do erro do resultado final
SeuDataFrame$error #o erro verdadeiro
```

Essa técnica Substitui temporariamente os NA por uma estimativa inicial,
geralmente a média (para variáveis numéricas) ou a moda (para
categóricas).

**Predição com Random Forest:**

-   Para cada variável com NA, ela é tratada como variável dependente
    (y).

-   As outras colunas sem NA são usadas como preditores (X).

-   Um modelo de Random Forest é treinado para prever os valores
    ausentes.

-   Os valores ausentes são substituídos pelas previsões do modelo.

**NRMSE (Normalized Root Mean Square)**

É o Erro quadrático médio normalizado, uma métrica usada para avaliar a
qualidade da imputação de valores ausentes quando utilizamos métodos
como missForest(). Ele mede o erro médio da imputação normalizado pelo
intervalo ou desvio padrão dos valores verdadeiros.

**Como interpretar o NRMSE?**

-   **NRMSE próximo de 0** → A imputação foi excelente (os valores
    imputados estão muito próximos dos valores reais).

-   **NRMSE entre 0.1 e 0.5** → A imputação é razoável, mas pode haver
    erros consideráveis.

-   **NRMSE \> 0.5** → A imputação tem alto erro e pode não ser
    confiável.

Em geral, quanto menor o NRMSE, melhor a imputação!

```{r, eval=FALSE}
library(missForest)

data(iris) # Conjunto de dados que não possuem valores ausentes.

set.seed(81) # Para padronização

iris.ausentes <- prodNA(iris, noNA = 0.2) 

any(is.na(iris.ausentes))
which(is.na(iris.ausentes), arr.ind = TRUE)
colSums(is.na(iris.ausentes))

iris.estimadosT <- missForest(iris.ausentes, xtrue = iris, verbose = TRUE) # verbose mostra o que a função está fazendo

```

**Estimativa do Erro**

```{r, eval=FALSE}
iris.estimadosT$OOBerror
```

**Estimativa verdadeira do Erro**

```{r, eval=FALSE}
iris.estimadosT$error
```

Se as estimativas dos erros estiverem confortáveis *(O PFC mostra a
porcentagem das variáveis que não foram corretamente estimadas)* salve
os dados em outro objeto:

```{r, eval=FALSE}
iris.estimados <- iris.estimados$ximp
```

**Comparar os resultados estimados com os valores reais:**

Podemos comparar diretamente (visualmente) as duas planilhas:

```{r, eval=FALSE}
# Criar uma máscara dos valores que foram imputados
mascara_NA <- is.na(iris.ausentes)

# Extrair apenas os valores imputados e seus valores reais correspondentes
valores_imputados <- iris.estimados[mascara_NA]
valores_reais <- iris[mascara_NA]

# Criar um data frame para visualizar as comparações
comparacao <- data.frame(
  Valor_Real = valores_reais,
  Valor_Imputado = valores_imputados
)

# Mostrar a tabela de comparação
print(comparacao)
```

**Técnicas descritivas e inferenciais para verificar a confiabilidade
dos valores imputados pelo Random Forest:**

Primeiro precisamos remover as variáveis categóricas, nesse primeiro
momento, iremos verificar a confiabilidade da privisão do modelo com
dados numéricos.

```{r, eval=FALSE}
# Filtrar apenas os valores numéricos (caso tenha variáveis categóricas)
valores_reais_num <- as.numeric(valores_reais)  
valores_imputados_num <- as.numeric(valores_imputados)

# Remover possíveis NAs que possam surgir ao converter os dados
valores_reais_num <- valores_reais_num[!is.na(valores_reais_num)]
valores_imputados_num <- valores_imputados_num[!is.na(valores_imputados_num)]

# Calcular variância e desvio padrão para os valores reais
var_real <- var(valores_reais_num)
sd_real <- sd(valores_reais_num)

# Calcular variância e desvio padrão para os valores imputados
var_imputado <- var(valores_imputados_num)
sd_imputado <- sd(valores_imputados_num)

# Criar um data frame com os resultados
resultado_variancia_desvio <- data.frame(
  Estatistica = c("Variância", "Desvio Padrão"),
  Valores_Reais = c(var_real, sd_real),
  Valores_Imputados = c(var_imputado, sd_imputado)
)

# Mostrar os resultados
print(resultado_variancia_desvio)
```

Nessa etapa percebemos que os dois conjuntos de dados possuem variações
próximas um do outro, mas para verificar se de fato essas variações são
homogêneas ou não, precisaremos utilizar algumas análises para primeiro
verificar a normalidade dos dados para só após aplicar um teste
inferencial.

**Verificar a normalidade dos dados:**

```{r, eval=FALSE}
shapiro_real <- shapiro.test(valores_reais_num)
shapiro_imputado <- shapiro.test(valores_imputados_num)

# Criar data frame com os resultados
resultado <- data.frame(
  Conjunto = c("Valores Reais", "Valores Imputados"),
  W_Statistic = c(shapiro_real$statistic, shapiro_imputado$statistic),
  p_Value = c(shapiro_real$p.value, shapiro_imputado$p.value)
)
return(resultado)
}
```

A função shapiro retorna uma tabela com os valores do teste estatístico
W e o p-valor associado ao teste. A hipótese nula do teste shapiro é que
os dados seguem uma **distribuição normal**, logo, se o p-valor for
maior que o alfa (nível de significância) *não rejeitamos a hipótese
nula e os dados são normais*.

Se o p-valor for menor que o alfa, nós rejeitamos a hipótese nula e os
dados não são normais.

O W (estatística do teste) mede o quanto os dados se aproximam de uma
distribuição normal. Quanto mais próximo de 1, mais próximo os dados
estão de uma distribuição normal. Valores altos de W pode indicar a
presença de outliers, ou até mesmo assimetria e curtose nos dados.

**Teste de Wilcoxon pareado para comparar os valores reais e imputados**

Como os dados não seguem uma distribuição normal dos dados, iremos
utilizar um teste não paramétrico para comparar as amostras antes e
depois da estimativa.

```{r, eval=FALSE}
wilcox_test <- wilcox.test(valores_reais_num, valores_imputados_num, paired = TRUE)

# Exibir o p-valor
print(wilcox_test$p.value)
```

Se p \< 0.05 → Indica que existem diferenças significativas entre os
grupos (rejeitamos a hipótese nula de que as distribuições são iguais).

O p-valor encontrado foi **0.059** que está ligeiramente acima de 0.05,
indicando que não há uma diferença estatisticamente significativa entre
os valores imputados e os valores reais, mas está bem próximo do limiar.

**Comparar as Variâncias - Teste de Levene**

```{r, eval=FALSE}
library(car)
leveneTest(c(valores_reais_num, valores_imputados_num), 
           group = rep(c("Reais", "Imputados"), 
                       c(length(valores_reais_num), length(valores_imputados_num))))
```

O p-valor indica que não existem diferenças significativas nas
variâncias dos grupos comparados.

**Tamanho de Efeito:** É uma medida estatística que quantifica a
**magnitude** de uma diferença ou relacionamento entre grupos ou
variáveis, independentemente do tamanho da amostra. Em outras palavras,
enquanto os testes de significância estatística (como o **teste t** ou
**ANOVA**) nos dizem se um efeito é **estatisticamente significativo**,
o **tamanho de efeito** nos ajuda a entender **quão grande ou
relevante** esse efeito é em termos práticos ou reais.

**Importância do Tamanho de Efeito**

1.  **Avaliação da Relevância Prática**: Embora um teste estatístico
    possa indicar que uma diferença entre grupos é **estatisticamente
    significativa**, o tamanho de efeito nos informa se essa diferença é
    **importante** na prática. Isso é crucial porque uma diferença
    pequena, mas estatisticamente significativa, pode não ter relevância
    prática em contextos do mundo real. O tamanho de efeito ajuda a
    evitar essa falácia, fornecendo uma visão mais clara do impacto
    real.

2.  **Comparação entre Estudos**: O tamanho de efeito permite comparar
    resultados de diferentes estudos, mesmo que eles tenham usado
    diferentes tamanhos de amostra. Isso é importante em metanálises,
    onde os dados de múltiplos estudos são combinados para tirar
    conclusões gerais. Quando você tem o tamanho de efeito, pode
    comparar a força de uma relação ou diferença em diferentes contextos
    e condições experimentais, independentemente da amostra.

3.  **Planejamento de Estudos**: O tamanho de efeito é fundamental para
    o **planejamento de pesquisas** e **cálculo do poder estatístico**.
    Ao conhecer o tamanho do efeito esperado, os pesquisadores podem
    determinar o tamanho da amostra necessário para detectar um efeito
    com uma probabilidade adequada (poder estatístico). Isso é crucial
    para garantir que os estudos não sejam nem excessivamente pequenos
    (não detectando um efeito verdadeiro) nem excessivamente grandes
    (com um custo desnecessário).

4.  **Interpretação de Resultados**: Em contextos acadêmicos e
    profissionais, o tamanho de efeito ajuda a **interpretar** a
    significância dos resultados de forma mais contextualizada. Um
    p-valor de 0.05, por exemplo, indica uma probabilidade de erro de
    5%, mas não fornece informações sobre a magnitude do efeito. Já o
    tamanho de efeito oferece uma medida mais direta de quão grande é o
    impacto observado.

5.  **Compreensão da Variabilidade**: O tamanho de efeito também ajuda a
    compreender a **variabilidade** entre grupos ou dentro de um
    conjunto de dados. Em vez de focar apenas em se a diferença é
    significativa ou não, o tamanho de efeito oferece uma visão mais
    detalhada da **intensidade** ou **força** dessa diferença. Esse tipo
    de compreensão é útil em várias áreas, como psicologia, biologia e
    ciências sociais, onde os efeitos pequenos, mas consistentes, podem
    ser mais importantes do que grandes efeitos que ocorrem raramente.

**Tipos de Tamanho de Efeito**

Existem várias formas de calcular o tamanho de efeito, e a escolha
depende do tipo de análise:

1.  **d de Cohen**: Mede a diferença entre duas médias em termos do
    desvio padrão. Um valor de 0.2 indica um efeito pequeno, 0.5 um
    efeito médio, e 0.8 um grande efeito.

2.  **r de Pearson**: Mede a força e a direção de uma relação linear
    entre duas variáveis. Um valor de 0.1 a 0.3 indica um efeito
    pequeno, 0.3 a 0.5 um efeito médio e 0.5 ou mais um grande efeito.

3.  **η² (eta quadrado)**: Usado em ANOVA para medir a proporção de
    variabilidade explicada pela variável independente.

4.  **Odds ratio e risco relativo**: Usados em estudos de caso-controle
    ou estudos epidemiológicos para medir a força da associação entre
    uma variável independente e um evento.

**Exemplo de Interpretação do Tamanho de Efeito**

Imaginemos um estudo que investiga a eficácia de um novo medicamento
comparado a um placebo. O teste estatístico pode indicar que a diferença
entre os dois grupos é **estatisticamente significativa** (p-valor \<
0.05), mas o tamanho de efeito pode ser pequeno, digamos, um **d de
Cohen = 0.2**. Isso sugere que, embora o medicamento tenha mostrado um
efeito significativo, a **magnitude** desse efeito é pequena, o que pode
implicar que, na prática, o medicamento tem pouco impacto em relação ao
placebo, apesar da diferença ser significativa.

Por outro lado, se o tamanho de efeito for **d = 0.8**, o efeito seria
considerado **grande**, o que indicaria que o medicamento tem um impacto
substancial e relevante em comparação com o placebo.

Já que utilizamos o teste de WIlcoxon, iremos utilizar o tamanho de
efeito apropriado a esse teste (para conjunto de dados não normais).

```{r, eval=FALSE}
library(rstatix)
library(coin)
dados <- data.frame(
  valores = c(valores_reais_num, valores_imputados_num),
  grupo = rep(c("Reais", "Imputados"), 
              c(length(valores_reais_num), length(valores_imputados_num)))
)

wilcox_effsize(dados, formula = valores ~ grupo)
```

O valor de efeito (0.0187) está muito próximo de zero e a classificação
como "small" sugere que, embora exista uma diferença entre os grupos
Imputados e Reais, essa diferença é muito pequena.

##### 5. **Imputação Múltipla (Multiple Imputation - Pacote mice no R)**

A imputação múltipla é uma técnica mais avançada e robusta, na qual os
valores ausentes são imputados várias vezes, criando diferentes
conjuntos de dados "imputados". Cada conjunto de dados é analisado
separadamente e as estimativas finais são combinadas de forma a refletir
a incerteza sobre os valores imputados.

-   **MICE (Multivariate Imputation by Chained Equations)**: Método
    popular de imputação múltipla, no qual um conjunto de equações é
    utilizado para imputar as variáveis ausentes uma de cada vez, de
    forma iterativa.

**Vantagens**:

-   Considera a incerteza associada aos valores imputados.

-   Produz estimativas mais precisas e conservadoras, especialmente em
    datasets complexos.

**Limitações**:

-   Requer conhecimento avançado em estatísticas.

-   Não é tão boa para dados categóricos.

-   Mais caro computacionalmente, pois envolve múltiplas imputações e
    análises.

##### 6. **Imputação com Redes Neurais (Pacote h2o no R)**

As redes neurais podem ser usadas para imputar dados faltantes,
especialmente em conjuntos de dados grandes e complexos. Redes neurais
artificiais podem aprender padrões complexos entre as variáveis para
prever valores ausentes.

**Vantagens**:

-   Capacidade de modelar relações não-lineares complexas entre as
    variáveis.

-   Pode ser eficaz em dados grandes e com muitos atributos.

**Limitações**:

-   Requer uma quantidade considerável de dados para ser eficaz.

-   Pode ser difícil de interpretar, tornando-a menos transparente que
    outros métodos.

##### **Conclusão**

A escolha do modelo de imputação depende do **tipo de dados**, da
**quantidade de dados ausentes**, do **objetivo da análise** e da
**complexidade computacional** que você está disposto a enfrentar.
Embora as técnicas simples como a imputação por média ou mediana possam
ser rápidas e fáceis de implementar, abordagens mais sofisticadas, como
**imputação múltipla** ou **MissForest**, são mais robustas e geralmente
fornecem resultados mais precisos e confiáveis, especialmente em
conjuntos de dados mais complexos.

Cada técnica tem suas vantagens e desvantagens, e é importante analisar
os dados de forma cuidadosa antes de escolher a abordagem mais
apropriada para o tratamento de dados ausentes.
